以下的langchain的版本为0.38

1、安装
pip install langchain-core langchain-community langchain-openai


3.1 LangChain的模块
3.1.1 模块
Model I/O 模块(语言模型 指令 输出解析器)
检索模块（向量数据及外部数据）
内存
链
代理（Agent）
回调



3.2
3.2.1 LangSmith
3.2.2 调试LLM应用
langchain.debug=True
langchain.verbose=True

3.3 langchain回退
有效的容错策略，旨在确保调用API失败或性能下降时，能维护正常的运行状态。
3.3.1 处理LLM调用API的错误
llmOpenAI=ChatOpenAI()
llmOllama=ChatOllama()
llm=llmOpenAI.with_fallbacks([llmOllama])

3.3.2
AsyncCallbacks.py 重点复习



4.1.6 缓存
1）内存缓存
from langchain_community.cache import InMemoryCache
from langchain.globals import set_llm_cache

langchain.llm_cache = InMemoryCache()
#set_llm_cache(InMemoryCache())
llm.invoke("first test cache")
llm.invoke("first test cache")

2)SQLite缓存
from langchain.cache import SQLiteCache
langchain.llm_cache=SQLiteCache(database_path=".langchain.db")
llm.invoke("first test cache")
llm.invoke("first test cache")

3)序列化LLM配置
llm.save("llm.json")
llm.save("llm.yaml")
from langchain_community.llms.loading import load_llm
load_llm(filename)

4)llm比较
from langchain.model_laboratory import ModelLaboratory
model_lab=ModelLaboratory.from_llms(llms)
model_lab.compare(message)


4.4 解析器
4.4.1 列表解析器
from langchain_core.output_parsers import CommaSeparatedListOutputParser
output_parser = CommaSeparatedListOutputParser()
format_instructions = output_parser.get_format_instructions()
prompt = PromptTemplate(
    template="List five {subject}.\n{format_instructions}",
    input_variables=["subject"],
    partial_variables={"format_instructions": format_instructions}
)
...
output_parser.parse(response.content)

4.4.2 日期时间解析器
from langchain.output_parsers import DatetimeOutputParser
prompt = PromptTemplate.from_template(template, partial_variables={"format_instructions": output_parser.get_format_instructions()})
prompt = PromptTemplate.from_template(template, partial_variables={
chain=prompt | llm

4.4.3 Json解析器


5.编写Prompt的策略
5.1 使用明确且具体的指令
5.2 添加明确的语法
  比如用：作为分隔符，对问题更好进行说明。
5.3 最后重复一遍指令
5.4 引导输出操作
5.5 引导输入格式
  比如： 回答“是的”或“不是”
5.6 细化任务的分解
5.7 思维链指令
5.8 提供真实的上下文 
5.9 限定结构化输出
5.10 指定完成任务所需的步骤
5.11 设定角色与人物

6.Prompt模板
1）字符串模板
PromptTemplate
PromptTemplate.from_template()

2）聊天指令模板
每条消息均包含内容，且附加role参数
ChatPromptTemplate
ChatPromptTemplate.from_message()

AIMessagePromptTemplate
SystemMessagePromptTemplate
HumanMessagePromptTemplate

ChatMessagePromptTemplate
1


7.数据
TextLoader
CSVLoader
DirectoryLoader
  use_multithreading=True
  loader_cls=[TextLoader|PythonLoader]
  silent_errors=True #skip error file
    text_load_kwargs={'autodetect_encoding': True} #文件编码自动检测
  loader_kwargs=text_load-kwargs
UnstructuredHTMLLoader

UnstructuredPDFLoader
  pdfminer要装pdfminer.six这个版本
  pi_heif
  unstructured_inference
  pdf2image

拆分
RecursiveCharacterTextSplitter
  length_function 计算长度的函数
  chunk_size 每个块的大小
  chunk_overlap 重叠块大小
  add_start_index 块中包含起始位置
  .from_language(lnaguage=Language.PYTHON,)

CharacterTextSplitter
  separator="\n\n"
  chunk_size 每个块的大小
  chunk_overlap 重叠块大小
  add_start_index 块中包含起始位置
  is_separator_regex

  length_function 计算长度的函数

8.2使用redis缓存向量
store = RedisStore(redis_url="redis://192.168.0.222:6379", client_kwargs={'db': 2}, namespace='embedding_caches')
underlying_embeddings = OllamaEmbeddings(model="nomic-embed-text", base_url=os.getenv("OLLAMA_URL"))
embedder = CacheBackedEmbeddings.from_bytes_store(
    underlying_embeddings, store, namespace=underlying_embeddings.model
)
embeddings = embedder.embed_documents(["hello", "goodbye"])
print(list(store.yield_keys()))


9.记忆
记忆的类型
1）会话内存
ConversationBufferMemory
2)滑动窗口内存
ConversationBufferWindowMemory
3)实体内存
ConversationEntityMemory
4)知识图谱会话内存
ConversationKGMemory
5)会话摘要内存
ConversationSummaryMemory
6)会话摘要缓存内存
ConversationSummaryBufferMemory
7)会话Token缓存内存
ConversationTokenBufferMemory
8)向量存储检索内存
VectorStoreRetrieverMemrory


11.工具
工具的关键要素。
1）名称：用以标识和引用。
2）描述：阐明工具的功能和用途。
3）JSON模式：定义了输入数据和结构和格式。
4）调用函数：实现具具体的功能。
5）标志：指示是否应直接将工具结果返回给用户。

内置工具：
Apify
Shell
Bing Search
File System
Memorize #微调LLM，以实现信息的记忆功能，需要支持微调的LLM
SQL Database




