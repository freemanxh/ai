tiktoken库用于计算字符串中token数的工具。

import os
from dotenv import load_dotenv

ollamaEmbedding = OllamaEmbeddings(model=os.getenv("OLLAMA_EMBEDDING"), base_url=os.getenv("OLLAMA_URL"))
ollama = ChatOllama(model=os.getenv("OLLAMA_MODEL"), base_url=os.getenv("OLLAMA_URL"))

.env
OLLAMA_EMBEDDING=bge-m3:latest
OLLAMA_URL=http://192.168.0.6:11434
OLLAMA_MODEL=qwen3:14b


1、模型I/O组件
1.1、模型包装器：通过接口调用大语言模型 
  1.1.1、LLM模型包装器 （字符串） BaseLLM 2023年7月之前。
  1.1.2、ChatLLM模型包装器 (消息输入、消息输出) BaseChatModel
1.2、提示词模板管理：输入 Model I
1.3、输出解析器：Model O

序列化是指将消息对象转换为可以存储或传输的数据模式过程。

1.4、提示词模版：（明确的指令、少量的示例、用户输入）
1.4.1、PromptTemplate实例化过程，就是构造提示词。

template=("""xxx{v1}xx""")
input_variables=["","",""]
The_PT=PromptTemplate(input_variables,template)

prompt=The_PT.format(v1="",v1="",v3="")  #format_prompt

最主要的外部数据有 用户的输入、用户和模型的历史聊天记录、外部知识数据、程序上下文管理信息。

实例化内置模板对象
from_template
from_message

在实例化模板对象后将外部用户输入格式化并传入对象内。
format
format_prompt

to_string
to_message

1.4.2、FewShotPromptTemplate
 示例选择器
  LengthBasedExampleSelector 基于长度
  MaxMarginalRelevanceExampleSelector 最大边际相关性
  NGramOverlapExampleSelector 基于n-gram重叠度
  SemanticSimilarityExampleSelector 基于相似度
1.4.3、多功能提示词模板
 Partial提示词模板
 PipelinePrompt组合模板功能
 序列化模板

1.5输出解析器 （结构化数据）
1.5.1、功能：添加提示词模板的输出指令和解析输出格式。
BooleanOutputParser
CommaSeparatedListOutputParser 以逗号分隔的列表类型的输出
DatetimeOutputParser 
EnumOutputParser
ListOutputParser
PydanticOutputParser
StructuredOutputParser

两个方法：
 get_format_instructions()
 parse()


1.5.2、Padantic Json输出解析器
from pydantic import BaseModel,Field,validator
class Joke(BaseModel):
  setup: str=Field(description="question to set up a joke")
  punchline: str=Field(description="answer to resolve the joke")
  #使用Pydantic添加自定义的验证逻辑
  def question_ends_with_question_mask(cls,field):
    if field[-1]!="?":
      raise ValueError("Badly formed question!")
    return field

parser=PydanticOutputParser(pydantic_object=Joke)




1.5.3、StructuredOutputParser
response_schemas=[
  ResponseSchema(
    name="answer",
    description="answer to the user's quesion"
  ),
  ResponseSchema(
    name="source",
    description=(
      "source used to answer the user's question,"
      "should be a website."
    )
  )
]
output_parser=StructuredOutputParser.from_response_schemas(response_schemas)
format_instructions=output_parser.get_format_instructions()

2、数据增加（RAG）
LEDVR 工作流
L Loader 
E Text Embedding Model
D Document Transformers 对文档进行切割、组合、过滤。 将加载的文档转换为可被嵌入模型包装器操作的文档数据格式。
  RecursiveCharacterTextSplitter 文本切割器
V VectorStore  最相似
R Retriever

文档数据：包含文本及相关元数据 向量数据

加载器
1、txt
  TextLoader
2、csv
  CSVLoader
3、文件目录
  DirectoryLoader
4、HTML
  BSHTMLLoader
5、JSON (jq)
  JSONLoader
6、Markdown
  UnstructuredMarkdownLoader
7、PDF
  MathpixPDFLoader
  UnstructuredPDFLoader
  OnlinePDFLoader
  PyPDFium2Loader
  PDFMinerLoader
  PyMuPDFLoader

三大模型包装器（Embeddings、LLM、Chat Model）
Embeddings 嵌入方法 
embed_documents 
embed_query


文档转换器
两个步骤：1、对文档进行切割。2、将切割后的文档转换为Document数据格式。

文档切割

文档切割的意义：1、LLM平台处理长文本的能力是有限的（token限制）
             2、文档作为一个整体无法充分发挥模型的作用。可能在语义上存在较大的差异。

RecursiveCharacterTextSplitter 
默认切割的字符：["\n\n","\n"," ",""]

按字符切割 CharacterTextSplitter
代码切割 RecursiveCharacterTextSplitter
Markdown标题文本切割 MarkdownHeaderTextSplitter
Token切割
  Tiktoken 标记切割器

向量存储库的搜索方法：
1、similarity_search(query: str,int =4)->List[Document]
2、similarity_search_by_vector(embedding:List[float],k: int=4) -> List[Document]
3、max_marginal_relevance_search(query: str,k: int=4,fetch_k: int =20,lambda_mult: float=0.5)->List[Document]
=========================================================================================

LEDVR的工作流的终点与目的：上链

LEDVR 例子：
from langchain.chains import RetrievalQA
from langchain.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain_community.chat_models import ChatOllama
from langchain_community.embeddings import OllamaEmbeddings
import os
from dotenv import load_dotenv

load_dotenv()

ollamaEmbedding = OllamaEmbeddings(model=os.getenv("OLLAMA_EMBEDDING"), base_url=os.getenv("OLLAMA_URL"))
ollama = ChatOllama(model=os.getenv("OLLAMA_MODEL"), base_url=os.getenv("OLLAMA_URL"))

#L
raw_documents = TextLoader("../chapter7_agent/state_of_the_union.txt").load()
#E
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
#D
documents = text_splitter.split_documents(raw_documents)
#V
db = FAISS.from_documents(documents, ollamaEmbedding)
#R
qa = RetrievalQA.from_chain_type(llm=ollama, chain_type="stuff", retriever=db.as_retriever())

#qa=ConversationalRetrievalChain.from_llm(llm=ollama,retriever=db.as_retriever())

query = "What did the president say about Ketanji Brown Jackson"
answer = qa.run(query)
print(answer)



5、Chain
链：用链将大语言模型开发的各个组件链接起来，以构建复杂的应用程序。是连接组件、管理组件数据流的"包装器"
主要功能是管理应用程序中的数据流动，将不同的组件链接在一起，形成一个完整的数据处理流程。每一个链都是由一系列组件构成的。
组件包括（模型I/O、记忆、回调处理、数据增强、Agent、链）

当链对象只有一个输出键（output_keys中只有一个元素）时，预期的结果是一个字符串，此时可以使用run方法。

__call__方法。
__call__方法中最有用的是下面3个参数：
inputs: 传递给链的输入。
return_only_outputs： True 只返回输出结果。 False 返回其它额外的信息。
callbacks：回调函数的列表，在链执行过程中的某些时刻被调用。

verbose=True 用于调试。


5.2 基础链类型：
LLMChain : 由提示词模板和模型包装器组成。
RouterChain :动态选择给定输入的下一条链。
SequentialChain :一次调用的输出作为另一次调用的输入。
 SimpleSequentialChain
 SequentialChain
TransformationChain :用于数据转换的链。
5.3 工具链类型：
APIChain
ConversationalRetrievalQA
MapReduceDocumentsChain
StuffDocumentsChain

ConstitutionalChain :输出遵循一定原则的链。

数据库操作：
from langchain_community.chat_models import ChatOllama
from langchain_community.utilities.sql_database import SQLDatabase
from langchain.agents import create_sql_agent
from langchain.agents.agent_toolkits import SQLDatabaseToolkit

import os
from dotenv import load_dotenv
load_dotenv()

db=SQLDatabase.from_uri("sqlite:///Chinook_Sqlite.sqlite")
ollamaLlm = ChatOllama(model=os.getenv("OLLAMA_MODEL"), base_url=os.getenv("OLLAMA_URL"))

# 创建工具包
toolkit = SQLDatabaseToolkit(db=db, llm=ollamaLlm)

# 创建代理
agent_executor = create_sql_agent(
    llm=ollamaLlm,
    toolkit=toolkit,
    verbose=True
)

# 执行自然语言查询
response = agent_executor.run("How many employees are there?")
print(response)


5.4 合并文档链 配合LEDVR工作流。
5.4.1 Stuff 链：文档较少且大部份调用只传入少量文档的应用程序。
5.4.2 Refine 链：通过遍历输入文档并迭代更新其答案来构建响应。适合上下文容纳不下的文档。
5.4.3 MapReduce 链：单独应用于每个文档（Map），把所有的输出作为新文档再传递给一个文档链（Reduce）。
5.4.4 MapRerank 链：除了完成一个任务，还要提供一个置信度得分，用于进行排序，提高系统的性能和准确性。

业务中，使用最多的是QA问答链、摘要链。


6、记忆模块
记忆组件的功能：读取和写入

内置记忆组件
ConversationBufferMemory
ConversationbufferWindowMemory
ConversationTokenBufferMemory
ConversationEntityMemory
ConversationKGMemory
CombinedMemory

ConversationSummaryBufferMemory
ConversationSummaryMemory

SQLChatMessageHistory
MongoDBChatMessageHistory
DynamoDBChatMessageHistory

7、Agent模块 
Agent核心是用大模型推理引擎能力，并根据这些推理来决定如何与外部工具交互及采取何种行动，效能和状态很大程度上都依赖于使用的提示词策略。故，Agent组件与工具密不可分。
内置不同类型的Agent组件：负责做计划决策，制定执行计划表
Tools组件、
Toolkits组件
AgentExecutor组件：负责执行

React(Reasoning and Acting 推理与行动) 使用大语言模型来选择合适的工具组件。然后，Agent组件执行选定的工具组件的操作，并观察结果。这些结果再次被反馈给大语言模型进一步的分析与决策。这个过程持续进行，直到达到某个停止条件。

ReAct框架的提示词策略。  （思考|行动|行动输入|观察可以重复N次）
提示词模板  输出解析器  工具集

Agent组件的类型
ZERO_SHOT_REACT_DESCRIPTION #根据工具描述选择工具组件
STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION #
CONVERSATIONAL_REACT_DESCRIPTION
CHAT_ZERO_SHOOT_REACT_DESCRIPTION
CHAT_CONVERSATIONAL_REACT_DESCRIPTION
SELF_ASK_WITH_SEARCH
REACT_DOCSTORE

对于内置的Agent组件类型，简化方法 initialize_agent, 不需要创建Agent组件实例，也不需要显示创建AgentExcecutor。
agent=initialize_agent(tools,llm,agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)

简单ReAct Agent实践

llm=OpenAI()
#加载内置的工具
tools=load_tools(["serpapi","llm-math"],llm=llm)
agent=initialize-agent(tools,llm,agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)
agent.run("Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?")

8、回调处理器
允许开发者在特定事件发生时执行自定义操作的机制。
目的：提供一个统一、模块化和可重用的机制，使开发者能够更轻松为链组件和Agent组件添加各种回调功能。
模块化与可重用性、灵活性、与其他组件紧密集成、可维护性。

核心：
callbacks=[]:提供具体的回调处理列表。
run_manager:管理和触发回调事件。

过程：
开始执行链组件阶段：
链组件执行中阶段：
触发回调阶段：
完成队段：

BaseCallbackHandler
LLM事件
on_llm_start
on_llm_new_token
on_llm_end
on_llm_error

on_chat_model_start

on_chain_start
on_chain_end
on_chain_error

on_tool_start
on_tool_end
on_tool_error

on_text
on_agent_action
on_agent_finish


大语言模型是基于概率的模型，它预测下一个词的可能性是基于训练数据中的统计信息。当模型为生成文本时，它实际上是在每个步骤中做出基于概率的决策。

引入外部数据：
1、大模型之前，只能依赖搜索。
2、补充知识。
3、修复幻觉。

著名应用
ChatPDF 
ChatDoc


==========================================================
create_tagging_chain
create_tagging_chain_pydantic

class PersonalDetails(BaseModel):
  name: str=Field(
    ...,
    description= "这里是用户输入的名字"
  )
  city: str=Field(
    ...,
    description= "这是用户输入的居住城市"
  )
  email: str=Field(
    ...,
    description= "这是用户输入的邮箱地址"
  )

chain=create_tagging_chain_pydantic(PersonalDetails,llm)
test1=chain.run("你好，我是徐辉，我住在上海浦东，我的邮箱是:liteali1987@XX.com")

文本嵌入：
词嵌入模型：Word2Vec GloVe
良好的词嵌入：1）相似的词应对应于接近的点（等效地对应于相似的分数）2）不同的词对应于相隔较远的点（等效地对应于明显不同的分数）
句子嵌入模型：BERT Doc2Vec

点积相似性：嵌入向量的点积大，相似度高，点积小，相似度低。
余弦相似性：基于向量间的夹角来衡量它们之间的相似度。适用于评估高维空间中的数据点之间的相似度。夹角越小，越相似。

注意力机制：准确处理多义词。此机制可以根据上下文为单词提供特定的向量，从而为单词提供上下文信息。为每个词提供一个上下文相关的向量。

Transformer模型
1.标记化：token
2.嵌入：
3.位置编码：保持原始的位置信息。
4.Transformer block：每个block包含（注意力组件和前馈组件）
5.注意力机制：为每个单词提供上下文信息。多头注意力机制，使用多个嵌入来修改向量并为它们添加上下文。
6.Softmax层：Transformer模型为所有单词输出分数，并为句子中最可能的下一个单词给出最高分数。Softmax层的作用是将这些分数转化为概率值。
7.后训练：在整体训练完成后，再对模型进行特定任务的训练。

语义搜索：文本嵌入与相似度计算。1）文本嵌入将单词转换为向量。2）使用相似性来找到响应中与查询对应的向量最相似的向量。3）输出与这个最相似的向量对应的响应。







10、集成
Langchain 的核心组件
Callbacks:
LLM包装器:
Document loaders: 文档加载与处理
Document transformers: 针对文档的处理和转换
聊天模型包装器：
Memory:
Retrievers: 信息检索
嵌入模型包装器：
Agent toolkit:
Tools:
Vector store:
Grouped by provider:

向量数据库：
chroma
pinecone
milvus


cohere

CSVAgent
PandasAgent
PowerBIAgent


11、NLP与机器学习基础
N-Gram：基于训练的概率模型，可以估计文本中词序列的概率分布。
Logistic回归：文本分类任务算法。
贝叶斯：使用概率预测输出类别的可能性的监督算法，使用贝叶斯定理。
markov：程序序列数据，预测随机变量序列的概率。

文本预处理
1）文本数据清理：
Tokenization-=
Normalization(规范化) 相似含义的多个单词标准化的过程，转化为单一的规范形式。
Stop Word Removal
Stemming(词干提取) 通过移除词的前缀和后缀来清理文本数据
Lemmatization(词形还原) 将一个词的各种曲折形式转化为基基本形式或词典形式。
2）从文本到向量的转换
文本向量化：为机器学习算法提供数值输入
One Hot Encoding（一热编码）：采用文本数据中的唯一单词并为每个单词生成向量。
Count Vectorizers（计数向量化器）：能捕获单词在文本数据中的出现概率。
Bag of Words（词袋模型）：提取文本数据特征的方法，不考虑单词出现的顺序。
N-Gram（N元模型）： 代表句子中彼此相邻的一系列单词或标记。
TF-IDF(词频-逆文档频率)：表示单词在文本中重要性的频率。
3）构建分类器
为输入数据分配一个类别或类。
评估：准确度、精确度、召回率、F1得分。

12、LangChain框架中的主要类
BasePromptTemplate
BaseLLM
BaseChatModel
BaseCallbackManager
Embeddings
Agent
AgentExecutor
Chain
BaseLoader
BaseChatMemory
StructuredOutputParser
  ArxivRetriever
BaseTool
  GoogleSerperAPIWrapper
VectorStore



OpenAI的主要应用场景
1、内容生成
2、摘要
3、分类、归类和情感分析
4、数据提取
5、翻译

https://github.com/openai/openai-quickstart-node
https://github.com/openai/openai-quickstart-python









































