1、模型I/O组件
1.1、模型包装器：通过接口调用大语言模型 
  1.1.1、LLM模型包装器 （字符串） BaseLLM 2023年7月之前。
  1.1.2、ChatLLM模型包装器 (消息输入、消息输出) BaseChatModel
1.2、提示词模板管理：输入 Model I
1.3、输出解析器：Model O

序列化是指将消息对象转换为可以存储或传输的数据模式过程。

1.4、提示词模版：（明确的指令、少量的示例、用户输入）
1.4.1、PromptTemplate实例化过程，就是构造提示词。

template=("""xxx{v1}xx""")
input_variables=["","",""]
The_PT=PromptTemplate(input_variables,template)

prompt=The_PT.format(v1="",v1="",v3="")  #format_prompt

最主要的外部数据有 用户的输入、用户和模型的历史聊天记录、外部知识数据、程序上下文管理信息。

实例化内置模板对象
from_template
from_message

在实例化模板对象后将外部用户输入格式化并传入对象内。
format
format_prompt

to_string
to_message

1.4.2、FewShotPromptTemplate
 示例选择器
  LengthBasedExampleSelector 基于长度
  MaxMarginalRelevanceExampleSelector 最大边际相关性
  NGramOverlapExampleSelector 基于n-gram重叠度
  SemanticSimilarityExampleSelector 基于相似度
1.4.3、多功能提示词模板
 Partial提示词模板
 PipelinePrompt组合模板功能
 序列化模板

1.5输出解析器 （结构化数据）
1.5.1、功能：添加提示词模板的输出指令和解析输出格式。
BooleanOutputParser
CommaSeparatedListOutputParser 以逗号分隔的列表类型的输出
DatetimeOutputParser 
EnumOutputParser
ListOutputParser
PydanticOutputParser
StructuredOutputParser

两个方法：
 get_format_instructions()
 parse()


1.5.2、Padantic Json输出解析器
from pydantic import BaseModel,Field,validator
class Joke(BaseModel):
  setup: str=Field(description="question to set up a joke")
  punchline: str=Field(description="answer to resolve the joke")
  #使用Pydantic添加自定义的验证逻辑
  def question_ends_with_question_mask(cls,field):
    if field[-1]!="?":
      raise ValueError("Badly formed question!")
    return field

parser=PydanticOutputParser(pydantic_object=Joke)




1.5.3、StructuredOutputParser
response_schemas=[
  ResponseSchema(
    name="answer",
    description="answer to the user's quesion"
  ),
  ResponseSchema(
    name="source",
    description=(
      "source used to answer the user's question,"
      "should be a website."
    )
  )
]
output_parser=StructuredOutputParser.from_response_schemas(response_schemas)
format_instructions=output_parser.get_format_instructions()

2、数据增加（RAG）
LEDVR 工作流
L Loader 
E Text Embedding Model
D Document Transformers 对文档进行切割、组合、过滤。 将加载的文档转换为可被嵌入模型包装器操作的文档数据格式。
  RecursiveCharacterTextSplitter 文本切割器
V VectorStore  最相似
R Retriever

文档数据：包含文本及相关元数据 向量数据

加载器
1、txt
  TextLoader
2、csv
  CSVLoader
3、文件目录
  DirectoryLoader
4、HTML
  BSHTMLLoader
5、JSON (jq)
  JSONLoader
6、Markdown
  UnstructuredMarkdownLoader
7、PDF
  MathpixPDFLoader
  UnstructuredPDFLoader
  OnlinePDFLoader
  PyPDFium2Loader
  PDFMinerLoader
  PyMuPDFLoader

三大模型包装器（Embeddings、LLM、Chat Model）
Embeddings 嵌入方法 
embed_documents 
embed_query


文档转换器
两个步骤：1、对文档进行切割。2、将切割后的文档转换为Document数据格式。

文档切割

文档切割的意义：1、LLM平台处理长文本的能力是有限的（token限制）
             2、文档作为一个整体无法充分发挥模型的作用。可能在语义上存在较大的差异。

RecursiveCharacterTextSplitter 
默认切割的字符：["\n\n","\n"," ",""]

按字符切割 CharacterTextSplitter
代码切割 RecursiveCharacterTextSplitter
Markdown标题文本切割 MarkdownHeaderTextSplitter
Token切割
  Tiktoken 标记切割器

向量存储库的搜索方法：
1、similarity_search(query: str,int =4)->List[Document]
2、similarity_search_by_vector(embedding:List[float],k: int=4) -> List[Document]
3、max_marginal_relevance_search(query: str,k: int=4,fetch_k: int =20,lambda_mult: float=0.5)->List[Document]
=========================================================================================

LEDVR 例子：
from langchain.chains import RetrievalQA
from langchain.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain_community.chat_models import ChatOllama
from langchain_community.embeddings import OllamaEmbeddings
import os
from dotenv import load_dotenv

load_dotenv()

ollamaEmbedding = OllamaEmbeddings(model=os.getenv("OLLAMA_EMBEDDING"), base_url=os.getenv("OLLAMA_URL"))
ollama = ChatOllama(model=os.getenv("OLLAMA_MODEL"), base_url=os.getenv("OLLAMA_URL"))

#L
raw_documents = TextLoader("../chapter7_agent/state_of_the_union.txt").load()
#E
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
#D
documents = text_splitter.split_documents(raw_documents)
#V
db = FAISS.from_documents(documents, ollamaEmbedding)
#R
qa = RetrievalQA.from_chain_type(llm=ollama, chain_type="stuff", retriever=db.as_retriever())

query = "What did the president say about Ketanji Brown Jackson"
answer = qa.run(query)
print(answer)



4、Chain
链：用链将大语言模型开发的各个组件链接起来，以构建复杂的应用程序。是连接组件、管理组件数据流的"包装器"
主要功能是管理应用程序中的数据流动，将不同的组件链接在一起，形成一个完整的数据处理流程。每一个链都是由一系列组件构成的。
组件包括（模型I/O、记忆、回调处理、数据增强、Agent、链）

当链对象只有一个输出键（output_keys中只有一个元素）时，预期的结果是一个字符串，此时可以使用run方法。

__call__方法。
__call__方法中最有用的是下面3个参数：
inputs: 传递给链的输入。
return_only_outputs： True 只返回输出结果。 False 返回其它额外的信息。
callbacks：回调函数的列表，在链执行过程中的某些时刻被调用。

verbose=True 用于调试。




















