微调能提高LLM的性能与效率，更好的理解特定领域的语言与术语，更准确地预测结果。
微调更好的适应不同的数据集与任务，提高其泛化能力与鲁棒性。

微调技术有两种
1、指令微调：提高大模型的能力。在自然语言格式的实例集合上微调训练后的大模型的技术。与有监督和多任务Prompt训练密切相关。先收集或构造指令格式的数据，其次使用这些格式化的实例以有监督的方式微调大模型。

2、对齐微调：将大模型的能力与人类的价值观或偏好对齐。

数据集：
2、处理数据集：
1）数据清洗。删除数据中的低质量部份。
2）数据过滤。过滤掉不符合模型训练目标的文本。（长度、语言、机器生成文本）
3）数据去重。
4）价值观控制。
5）个人信息脱敏。

3、数据集标注：转换成大模型特定的输入格式。
 3.1、典型格式（llama2 不知能不能通用）指令微调：
{"instruction":"","input":"","output":""}
instruction:指对LLM的任务描述或指导。可以是一个问题、一个命令、一个任务描述。完成什么样的任务与目标。
input:输入大模型的数据。可以是一个文本、一句话、一个图像。
output:根据输入数据生成的结果。可以是一个回答、一个分类标签、一个生成的文本。
3.2、对话微调格式。
"<s>Human: "+问题+"\n</s><s>Assistant: "+答案
问题：用户输入的问题。
答案：对话系统返回的答案。




