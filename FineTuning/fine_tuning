微调能提高LLM的性能与效率，更好的理解特定领域的语言与术语，更准确地预测结果。
微调更好的适应不同的数据集与任务，提高其泛化能力与鲁棒性。

微调技术有两种
1、指令微调：提高大模型的能力。在自然语言格式的实例集合上微调训练后的大模型的技术。与有监督和多任务Prompt训练密切相关。先收集或构造指令格式的数据，其次使用这些格式化的实例以有监督的方式微调大模型。

2、对齐微调：将大模型的能力与人类的价值观或偏好对齐。

数据集：
2、处理数据集：
1）数据清洗。删除数据中的低质量部份。
2）数据过滤。过滤掉不符合模型训练目标的文本。（长度、语言、机器生成文本）
3）数据去重。
4）价值观控制。
5）个人信息脱敏。

3、数据集标注：转换成大模型特定的输入格式。
 3.1、典型格式（llama2 不知能不能通用）指令微调：
{"instruction":"","input":"","output":""}
instruction:指对LLM的任务描述或指导。可以是一个问题、一个命令、一个任务描述。完成什么样的任务与目标。
input:输入大模型的数据。可以是一个文本、一句话、一个图像。
output:根据输入数据生成的结果。可以是一个回答、一个分类标签、一个生成的文本。
3.2、对话微调格式。
"<s>Human: "+问题+"\n</s><s>Assistant: "+答案
问题：用户输入的问题。
答案：对话系统返回的答案。 
























======================================================================================================

https://zhuanlan.zhihu.com/p/713141442

微调不是万能的。根据OpenAI的官方介绍，微调适用于以下五种情况：

调整写作风格、语气、格式等
提高生成正确结果的稳定性
修正模型在复杂提示下的表现
处理一些特殊的、意外的情况
学习和执行在提示中无法明确说明的新技能或任务



那么做Fine-Tune的话就是下面几个步骤：

确定进行微调的模型
准备并上传训练数据
训练新的微调模型
评估结果并根据需要是否重新训练
使用您的微调模型


我在对OpenAI的API做微调的时候，碰到的最大问题就在于准备数据集上，因为其他步骤基本是都是自动化的，数据集的质量好坏其实决定了微调后模型的好坏。我失败了好几次的原因就是因为数据集的格式不对，它不是普通的json格式，而是jsonl格式，这一点儿我会在后面单独提到。








