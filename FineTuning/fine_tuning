微调能提高LLM的性能与效率，更好的理解特定领域的语言与术语，更准确地预测结果。
微调更好的适应不同的数据集与任务，提高其泛化能力与鲁棒性。

微调技术有两种
1、指令微调：提高大模型的能力。在自然语言格式的实例集合上微调训练后的大模型的技术。与有监督和多任务Prompt训练密切相关。先收集或构造指令格式的数据，其次使用这些格式化的实例以有监督的方式微调大模型。

2、对齐微调：将大模型的能力与人类的价值观或偏好对齐。


